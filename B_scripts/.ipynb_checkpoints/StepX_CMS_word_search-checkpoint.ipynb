{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What this script does"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dataset of all deficiencies committed by WA-based nursing homes from 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. IMPORT DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deficienies (CMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain a list of all the downloaded adult family PDF reports\n",
    "source_path = '../../covid19_nursing_homes_big_data/Full-Statement-of-Deficiencies-June-2020/'\n",
    "file_list = listdir(source_path)\n",
    "\n",
    "# Weed out any files in the folder that are not PDFs\n",
    "file_list = [file for file in file_list if re.search('\\.xlsx$', file)]\n",
    "file_list = pd.Series(file_list)\n",
    "\n",
    "df_sod_orig = pd.DataFrame()\n",
    "\n",
    "for file in file_list:\n",
    "    print(file)\n",
    "    df_temp = pd.read_excel(source_path + file,\n",
    "                            header=0, \n",
    "                            usecols=range(0,13), \n",
    "                            dtype={'facility_id':object, 'zip':object, 'deficiency_tag':object})\n",
    "    df_sod_orig = pd.concat([df_sod_orig, df_temp])\n",
    "    del(df_temp)\n",
    "\n",
    "df_sod_orig = df_sod_orig.reset_index(drop=True)\n",
    "\n",
    "# Save down a CSV version\n",
    "df_sod_orig.to_csv('../../covid19_nursing_homes_big_data/cms_sod_txt.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F-Tags (CMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SOD dataframe above contains tha tag code for each defficiency recorded, but it doesn't contain the general group that each of those tag belongs to. The information is containd in [this list of the revised F-tags](https://www.cms.gov/Medicare/Provider-Enrollment-and-Certification/GuidanceforLawsAndRegulations/Downloads/List-of-Revised-FTags.pdf). \n",
    "\n",
    "A version is in this [F-Tag crosswalk Excel file](https://www.cms.gov/Medicare/Provider-Enrollment-and-Certification/GuidanceforLawsAndRegulations/Downloads/F-Tag-Crosswalk.xlsx). This is the data we are importing now and that will be adding to the SOD dataset later in the script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tags_orig = pd.read_excel('../A_source_data/CMS/LTC FTags_Phase 2_Crosswalk.xlsx',\n",
    "                             sheet_name='Sortable by Tags', usecols='A:H')\n",
    "df_tags_orig.columns = ['tag', 'sqc_tag?', 'tag_title', 'cfr', 'tag_group', 'phase3', 'tag_old', 'moved_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have a data frame that contains all the deficiencies found in all surveys carried out, and another dataframe that contains detailed information about the tags used to classify those deficiencies. We need to join both dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sod_orig.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Severity code descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SOD dataframe also contains codes for the severity of each deficiency, but not a description of the severity level of each of those codes. Those descriptions can be found in the docment [Design for Nursing Home Compare\n",
    "Five-Star Quality Rating System:\n",
    "Technical Usersâ€™ Guide](https://www.cms.gov/Medicare/Provider-Enrollment-and-Certification/CertificationandComplianc/downloads/usersguide.pdf). The following mapping is based on that document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity = [['A', 'No actual harm with potential for minimal harm - Isolated'],\n",
    "            ['B', 'No actual harm with potential for minimal harm - Pattern'],\n",
    "            ['C', 'No actual harm with potential for minimal harm - Widespread'],\n",
    "            ['D', 'No actual harm with potential for more than minimal harm that is not immediate jeopardy - Isolated'],\n",
    "            ['E', 'No actual harm with potential for more than minimal harm that is not immediate jeopardy - Pattern'],\n",
    "            ['F', 'No actual harm with potential for more than minimal harm that is not immediate jeopardy - Widespread'],\n",
    "            ['G', 'Actual harm that is not immediate jeopardy - Isolated'],\n",
    "            ['H', 'Actual harm that is not immediate jeopardy - Pattern'],\n",
    "            ['I', 'Actual harm that is not immediate jeopardy - Widespread'],\n",
    "            ['J', 'Immediate jeopardy to resident health or safety - Isolated'],\n",
    "            ['K', 'Immediate jeopardy to resident health or safety - Pattern'],\n",
    "            ['L', 'Immediate jeopardy to resident health or safety - Widespread']]\n",
    "\n",
    "severity = pd.DataFrame(severity, columns=['scope_severity', 'severity_desc'])\n",
    "severity\n",
    "\n",
    "# Consitency test\n",
    "assert set(df_sod_orig['scope_severity']).issubset(set(severity['scope_severity']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. REDUCING: WA STATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del(df_sod_wa)\n",
    "df_sod_wa = df_sod_orig.copy()\n",
    "print(df_sod_wa.shape)\n",
    "\n",
    "# Reduce to only WA homes\n",
    "df_sod_wa = df_sod_wa[df_sod_wa['state'] == 'WA']\n",
    "print(df_sod_wa.shape)\n",
    "\n",
    "# Add the severity descriptions\n",
    "df_sod_wa = df_sod_wa.join(severity.set_index('scope_severity'), on='scope_severity', how='left')\n",
    "\n",
    "# Create a proper date column\n",
    "df_sod_wa['inspection_dt'] = pd.to_datetime(df_sod_wa['inspection_date'])\n",
    "\n",
    "# Eliminate unnecesary fields and reset index\n",
    "df_sod_wa = df_sod_wa.drop(['address', 'city', 'state', 'zip', 'inspection_date'], axis=1)\n",
    "df_sod_wa = df_sod_wa.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Change some column names into something easier to use\n",
    "df_sod_wa = df_sod_wa.rename(columns={'deficiency_tag':'tag', \n",
    "                                      'scope_severity':'severity_code'})\n",
    "\n",
    "print(df_sod_wa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sod_wa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. KEYWORD SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sod_wa.to_csv('/Users/mvilla/Downloads/full_text_sod_wa.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwds = [\"resident council\", \"call light\", \"short staff\", \n",
    "        \"resident and family interviews\", \"staff interviews\", \"resident interviews\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k in kwds:\n",
    "    df_temp = df_sod_wa[df_sod_wa['inspection_text'].str.lower().str.contains(k)]\n",
    "    print(k)\n",
    "    print(df_temp['facility_name'].value_counts(dropna=False).head(20))\n",
    "    print('\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwds = 'resident council|call light|short staff|resident and family interviews|staff interviews|resident interviews'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sod_wa_kwd = df_sod_wa[df_sod_wa['inspection_text'].str.lower().str.contains(kwds)]\n",
    "df_sod_wa_kwd = df_sod_wa_kwd.drop(['complaint','standard','eventid','severity_desc'], axis=1)\n",
    "df_sod_wa_kwd = df_sod_wa_kwd.sort_values(['facility_name','inspection_dt'])\n",
    "df_sod_wa_kwd = df_sod_wa_kwd[['facility_name','facility_id','tag','severity_code','inspection_text','inspection_dt','tag','severity_code']]\n",
    "df_sod_wa_kwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sod_wa_kwd.to_csv('/Users/mvilla/Downloads/full_text_sod_wa_kwds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
